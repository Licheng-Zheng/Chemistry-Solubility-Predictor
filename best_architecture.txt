{'layers': 3, 'sizes': [96, 96, 96], 'activations': ['leakyrelu', 'elu', 'sigmoid'], 'batch_norm': False, 'learning_rate': 0.001, 'batch_size': 22}